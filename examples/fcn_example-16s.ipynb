{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_kernel_size(factor):\n",
    "    \"\"\"\n",
    "    Find the kernel size given the desired factor of upsampling.\n",
    "    \"\"\"\n",
    "    return 2 * factor - factor % 2\n",
    "\n",
    "\n",
    "def upsample_filt(size):\n",
    "    \"\"\"\n",
    "    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "    \"\"\"\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    return (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "\n",
    "def bilinear_upsample_weights(factor, number_of_classes):\n",
    "    \"\"\"\n",
    "    Create weights matrix for transposed convolution with bilinear filter\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "    \n",
    "    filter_size = get_kernel_size(factor)\n",
    "    \n",
    "    weights = np.zeros((filter_size,\n",
    "                        filter_size,\n",
    "                        number_of_classes,\n",
    "                        number_of_classes), dtype=np.float32)\n",
    "    \n",
    "    upsample_kernel = upsample_filt(filter_size)\n",
    "    \n",
    "    for i in xrange(number_of_classes):\n",
    "        \n",
    "        weights[:, :, i, i] = upsample_kernel\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "sys.path.append(\n",
    "    os.path.expanduser(\"~/source/models/research/slim/\"))\n",
    "\n",
    "from nets import vgg\n",
    "from preprocessing import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "checkpoints_dir = os.path.expanduser('data/pre_trained/')\n",
    "\n",
    "image_filename = 'data/object_2.jpg'\n",
    "annotation_filename = 'data/segment_2.png'\n",
    "\n",
    "\n",
    "fig_size = [15, 4]\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "image_filename_placeholder = tf.placeholder(tf.string)\n",
    "annotation_filename_placeholder = tf.placeholder(tf.string)\n",
    "is_training_placeholder = tf.placeholder(tf.bool)\n",
    "\n",
    "feed_dict_to_use = {image_filename_placeholder: image_filename,\n",
    "                    annotation_filename_placeholder: annotation_filename,\n",
    "                    is_training_placeholder: True}\n",
    "\n",
    "image_tensor = tf.read_file(image_filename_placeholder)\n",
    "annotation_tensor = tf.read_file(annotation_filename_placeholder)\n",
    "\n",
    "image_tensor = tf.image.decode_jpeg(image_tensor, channels=3)\n",
    "annotation_tensor = tf.image.decode_png(annotation_tensor, channels=1)\n",
    "\n",
    "# Get ones for each class instead of a number -- we need that\n",
    "# for cross-entropy loss later on. Sometimes the groundtruth\n",
    "# masks have values other than 1 and 0. \n",
    "class_labels_tensor = tf.greater_equal(annotation_tensor, 1)\n",
    "background_labels_tensor = tf.less(annotation_tensor, 1)\n",
    "\n",
    "# Convert the boolean values into floats -- so that\n",
    "# computations in cross-entropy loss is correct\n",
    "bit_mask_class = tf.to_float(class_labels_tensor)\n",
    "bit_mask_background = tf.to_float(background_labels_tensor)\n",
    "\n",
    "combined_mask = tf.concat(axis=2, values=[bit_mask_background,\n",
    "                                          bit_mask_class,])\n",
    "\n",
    "# Lets reshape our input so that it becomes suitable for \n",
    "# tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mean pixel values and the function\n",
    "# that performs the subtraction from each pixel\n",
    "from preprocessing.vgg_preprocessing import (_mean_image_subtraction,\n",
    "                                            _R_MEAN, _G_MEAN, _B_MEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改最终的upsample_factor。这也是为什么称为FCN-16s的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_factor = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 2\n",
    "log_folder = os.path.expanduser('segment_log_folder')\n",
    "\n",
    "vgg_checkpoint_path = os.path.join(checkpoints_dir, 'vgg_16.ckpt')\n",
    "\n",
    "# Convert image to float32 before subtracting the\n",
    "# mean pixel value\n",
    "image_float = tf.to_float(image_tensor, name='ToFloat')\n",
    "\n",
    "original_shape = tf.shape(image_float)[0:2]\n",
    "\n",
    "# Subtract the mean pixel value from each pixel\n",
    "mean_centered_image = _mean_image_subtraction(image_float,\n",
    "                                          [_R_MEAN, _G_MEAN, _B_MEAN])\n",
    "\n",
    "target_input_size_factor = tf.ceil(\n",
    "    tf.div(tf.to_float(original_shape),\n",
    "           tf.to_float(upsample_factor)))\n",
    "target_input_size = tf.to_int32(tf.multiply(target_input_size_factor, upsample_factor))\n",
    "padding_size =(target_input_size - original_shape) // 2\n",
    "\n",
    "\n",
    "\n",
    "mean_centered_image = tf.image.pad_to_bounding_box(mean_centered_image,\n",
    "                                                  padding_size[0],\n",
    "                                                  padding_size[1],\n",
    "                                                  target_input_size[0],\n",
    "                                                  target_input_size[1])\n",
    "\n",
    "processed_images = tf.expand_dims(mean_centered_image, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model that we want to use -- specify to use only two classes at the last layer\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    \n",
    "    logits, end_points = vgg.vgg_16(processed_images,\n",
    "                           num_classes=2,\n",
    "                           is_training=is_training_placeholder,\n",
    "                           spatial_squeeze=False,\n",
    "                           fc_conv_padding='SAME')\n",
    "print(end_points)\n",
    "\n",
    "downsampled_logits_shape = tf.shape(logits)\n",
    "\n",
    "# Calculate the ouput size of the upsampled tensor\n",
    "upsampled_logits_shape = tf.stack([\n",
    "                                  downsampled_logits_shape[0],\n",
    "                                  original_shape[0],#downsampled_logits_shape[1] * upsample_factor,\n",
    "                                  original_shape[1],#downsampled_logits_shape[2] * upsample_factor,\n",
    "                                  downsampled_logits_shape[3]\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#对pool4进行1x1卷积\n",
    "#vgg的输出logit进行2x upsampling\n",
    "#将1和2的结果fuse(加和）\n",
    "#结果再进行16x upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool4_feature = end_points['vgg_16/pool4']\n",
    "with tf.variable_scope('vgg_16/fc8'):\n",
    "    aux_logits_16s = slim.conv2d(pool4_feature, 2, [1, 1], \n",
    "                             activation_fn=None,\n",
    "                             weights_initializer=tf.zeros_initializer,\n",
    "                             scope='conv_pool4')\n",
    "\n",
    "# Perform the upsampling\n",
    "upsample_filter_np_x2 = bilinear_upsample_weights(2, #upsample_factor,\n",
    "                                               number_of_classes)\n",
    "\n",
    "upsample_filter_tensor_x2 = tf.Variable(upsample_filter_np_x2, name='vgg_16/fc8/t_conv_x2')\n",
    "\n",
    "upsampled_logits = tf.nn.conv2d_transpose(logits, upsample_filter_tensor_x2,\n",
    "                                 output_shape=tf.shape(aux_logits_16s),\n",
    "                                 strides=[1, 2, 2, 1],\n",
    "                                         padding='SAME')\n",
    "\n",
    "\n",
    "upsampled_logits = upsampled_logits + aux_logits_16s\n",
    "\n",
    "upsample_filter_np_x16 = bilinear_upsample_weights(upsample_factor,\n",
    "                                               number_of_classes)\n",
    "\n",
    "upsample_filter_tensor_x16 = tf.Variable(upsample_filter_np_x16, name='vgg_16/fc8/t_conv_x16')\n",
    "upsampled_logits = tf.nn.conv2d_transpose(upsampled_logits, upsample_filter_tensor_x16,\n",
    "                                 output_shape=upsampled_logits_shape,\n",
    "                                 strides=[1, upsample_factor, upsample_factor, 1],\n",
    "                                         padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Flatten the predictions, so that we can compute cross-entropy for\n",
    "# each pixel and get a sum of cross-entropies.\n",
    "flat_logits = tf.reshape(tensor=upsampled_logits, shape=(-1, number_of_classes))\n",
    "\n",
    "\n",
    "cross_entropies = tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits,\n",
    "                                                          labels=flat_labels)\n",
    "\n",
    "cross_entropy_sum = tf.reduce_sum(cross_entropies)\n",
    "\n",
    "# Tensor to get the final prediction for each pixel -- pay \n",
    "# attention that we don't need softmax in this case because\n",
    "# we only need the final decision. If we also need the respective\n",
    "# probabilities we will have to apply softmax.\n",
    "pred = tf.argmax(upsampled_logits, axis=3)\n",
    "\n",
    "probabilities = tf.nn.softmax(upsampled_logits)\n",
    "\n",
    "# Here we define an optimizer and put all the variables\n",
    "# that will be created under a namespace of 'adam_vars'.\n",
    "# This is done so that we can easily access them later.\n",
    "# Those variables are used by adam optimizer and are not\n",
    "# related to variables of the vgg model.\n",
    "\n",
    "# We also retrieve gradient Tensors for each of our variables\n",
    "# This way we can later visualize them in tensorboard.\n",
    "# optimizer.compute_gradients and optimizer.apply_gradients\n",
    "# is equivalent to running:\n",
    "# train_step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cross_entropy_sum)\n",
    "with tf.variable_scope(\"adam_vars\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "    gradients = optimizer.compute_gradients(loss=cross_entropy_sum)\n",
    "    \n",
    "    for grad_var_pair in gradients:\n",
    "        \n",
    "        current_variable = grad_var_pair[1]\n",
    "        current_gradient = grad_var_pair[0]\n",
    "        \n",
    "        # Relace some characters from the original variable name\n",
    "        # tensorboard doesn't accept ':' symbol\n",
    "        gradient_name_to_save = current_variable.name.replace(\":\", \"_\")\n",
    "        \n",
    "        # Let's get histogram of gradients for each layer and\n",
    "        # visualize them later in tensorboard\n",
    "        tf.summary.histogram(gradient_name_to_save, current_gradient) \n",
    "    \n",
    "    train_step = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "    \n",
    "# Now we define a function that will load the weights from VGG checkpoint\n",
    "# into our variables when we call it. We exclude the weights from the last layer\n",
    "# which is responsible for class predictions. We do this because \n",
    "# we will have different number of classes to predict and we can't\n",
    "# use the old ones as an initialization.\n",
    "vgg_except_fc8_weights = slim.get_variables_to_restore(exclude=['vgg_16/fc8', 'adam_vars'])\n",
    "\n",
    "# Here we get variables that belong to the last layer of network.\n",
    "# As we saw, the number of classes that VGG was originally trained on\n",
    "# is different from ours -- in our case it is only 2 classes.\n",
    "vgg_fc8_weights = slim.get_variables_to_restore(include=['vgg_16/fc8'])\n",
    "\n",
    "adam_optimizer_variables = slim.get_variables_to_restore(include=['adam_vars'])\n",
    "\n",
    "# Add summary op for the loss -- to be able to see it in\n",
    "# tensorboard.\n",
    "tf.summary.scalar('cross_entropy_loss', cross_entropy_sum)\n",
    "\n",
    "# Put all summary ops into one op. Produces string when\n",
    "# you run it.\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "# Create the summary writer -- to write all the logs\n",
    "# into a specified file. This file can be later read\n",
    "# by tensorboard.\n",
    "summary_string_writer = tf.summary.FileWriter(log_folder)\n",
    "\n",
    "# Create the log folder if doesn't exist yet\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "\n",
    "# Create an OP that performs the initialization of\n",
    "# values of variables to the values from VGG.\n",
    "read_vgg_weights_except_fc8_func = slim.assign_from_checkpoint_fn(\n",
    "                                   vgg_checkpoint_path,\n",
    "                                   vgg_except_fc8_weights)\n",
    "\n",
    "# Initializer for new fc8 weights -- for two classes.\n",
    "vgg_fc8_weights_initializer = tf.variables_initializer(vgg_fc8_weights)\n",
    "\n",
    "# Initializer for adam variables\n",
    "optimization_variables_initializer = tf.variables_initializer(adam_optimizer_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess_config=tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=sess_config)\n",
    "\n",
    "with sess:\n",
    "    \n",
    "    # Run the initializers.\n",
    "    sess.run(vgg_fc8_weights_initializer)\n",
    "    sess.run(optimization_variables_initializer)\n",
    "    read_vgg_weights_except_fc8_func(sess)\n",
    "    \n",
    "    train_image, train_annotation = sess.run([image_tensor, annotation_tensor],\n",
    "                                              feed_dict=feed_dict_to_use)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "    ax1.imshow(train_image)\n",
    "    ax1.set_title('Input image')\n",
    "    probability_graph = ax2.imshow(np.dstack((train_annotation,)*3)*100)\n",
    "    ax2.set_title('Input Ground-Truth Annotation')\n",
    "    plt.show()\n",
    "    \n",
    "    # Let's perform 10 interations\n",
    "    for i in range(10):\n",
    "        loss, summary_string = sess.run([cross_entropy_sum, merged_summary_op],\n",
    "                                        feed_dict=feed_dict_to_use)\n",
    "        \n",
    "        sess.run(train_step, feed_dict=feed_dict_to_use)\n",
    "        \n",
    "        pred_np, probabilities_np = sess.run([pred, probabilities],\n",
    "                                              feed_dict=feed_dict_to_use)\n",
    "        \n",
    "        summary_string_writer.add_summary(summary_string, i)\n",
    "        \n",
    "        cmap = plt.get_cmap('bwr')\n",
    "        \n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "        ax1.imshow(np.uint8(pred_np.squeeze() != 1), vmax=1.5, vmin=-0.4, cmap=cmap)\n",
    "        ax1.set_title('Argmax. Iteration # ' + str(i))\n",
    "        probability_graph = ax2.imshow(probabilities_np.squeeze()[:, :, 0])\n",
    "        ax2.set_title('Probability of the Class. Iteration # ' + str(i))\n",
    "        mask = np.multiply(np.uint32(pred_np.squeeze()), 128)\n",
    "        mask = np.stack([mask,]*3, axis=-1)\n",
    "        masked_image = np.uint8(np.clip(train_image+mask, 0, 255))\n",
    "        probability_graph = ax3.imshow(masked_image)\n",
    "        plt.colorbar(probability_graph)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Current Loss: \" +  str(loss))\n",
    "    \n",
    "    feed_dict_to_use[is_training_placeholder] = False\n",
    "    \n",
    "    final_predictions, final_probabilities, final_loss = sess.run([pred,\n",
    "                                                                   probabilities,\n",
    "                                                                   cross_entropy_sum],\n",
    "                                                         feed_dict=feed_dict_to_use)\n",
    "    \n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "    \n",
    "    ax1.imshow(np.uint8(final_predictions.squeeze() != 1),\n",
    "               vmax=1.5,\n",
    "               vmin=-0.4,\n",
    "               cmap=cmap)\n",
    "    \n",
    "    ax1.set_title('Final Argmax')\n",
    "    \n",
    "    \n",
    "    probability_graph = ax2.imshow(final_probabilities.squeeze()[:, :, 0])\n",
    "    ax2.set_title('Final Probability of the Class')\n",
    "    plt.colorbar(probability_graph)\n",
    "    \n",
    "    mask = np.multiply(np.uint32(final_predictions.squeeze()), 128)\n",
    "    #mask = np.stack([mask,]*3, axis=-1)\n",
    "    mask = np.stack([np.zeros(mask.shape),\n",
    "                 mask,\n",
    "                 np.zeros(mask.shape)], axis=-1)\n",
    "    masked_image = np.uint8(np.clip(train_image+mask, 0, 255))\n",
    "    probability_graph = ax3.imshow(masked_image)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Loss: \" +  str(final_loss))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "summary_string_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对结果进行CRF处理。\n",
    "使用了cython版本的crf，源代码：\n",
    "[github](https://github.com/lucasb-eyer/pydensecrf/tree/94d1cddab277e6e93812dfe7daca7d4693560758)\n",
    "\n",
    "安装方法：\n",
    "`pip install git+https://github.com/lucasb-eyer/pydensecrf.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n",
    "    create_pairwise_gaussian, softmax_to_unary\n",
    "\n",
    "\n",
    "    \n",
    "image = train_image\n",
    "\n",
    "processed_probabilities = final_probabilities.squeeze()\n",
    "\n",
    "softmax = processed_probabilities.transpose((2, 0, 1))\n",
    "\n",
    "# The input should be the negative of the logarithm of probability values\n",
    "# Look up the definition of the softmax_to_unary for more information\n",
    "unary = softmax_to_unary(softmax)\n",
    "print(unary.shape)\n",
    "# The inputs should be C-continious -- we are using Cython wrapper\n",
    "unary = np.ascontiguousarray(unary)\n",
    "\n",
    "d = dcrf.DenseCRF(image.shape[0] * image.shape[1], 2)\n",
    "\n",
    "d.setUnaryEnergy(unary)\n",
    "\n",
    "# This potential penalizes small pieces of segmentation that are\n",
    "# spatially isolated -- enforces more spatially consistent segmentations\n",
    "feats = create_pairwise_gaussian(sdims=(10, 10), shape=image.shape[:2])\n",
    "\n",
    "d.addPairwiseEnergy(feats, compat=3,\n",
    "                    kernel=dcrf.DIAG_KERNEL,\n",
    "                    normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "# This creates the color-dependent features --\n",
    "# because the segmentation that we get from CNN are too coarse\n",
    "# and we can use local color features to refine them\n",
    "feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n",
    "                                   img=image, chdim=2)\n",
    "\n",
    "d.addPairwiseEnergy(feats, compat=10,\n",
    "                     kernel=dcrf.DIAG_KERNEL,\n",
    "                     normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "Q = d.inference(5)\n",
    "\n",
    "res = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
    "\n",
    "cmap = plt.get_cmap('bwr')\n",
    "\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "ax1.imshow(res, vmax=1.5, vmin=-0.4, cmap=cmap)\n",
    "ax1.set_title('Segmentation with CRF post-processing')\n",
    "probability_graph = ax2.imshow(np.dstack((train_annotation,)*3)*100)\n",
    "ax2.set_title('Ground-Truth Annotation')\n",
    "\n",
    "mask = np.multiply(np.uint32(res.squeeze()), 128)\n",
    "mask = np.stack([np.zeros(mask.shape),\n",
    "                 mask,\n",
    "                 np.zeros(mask.shape)], axis=-1)\n",
    "masked_image = np.uint8(np.clip(np.uint32(train_image)+mask, 0, 255))\n",
    "probability_graph = ax3.imshow(masked_image)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "intersection = np.logical_and(res, train_annotation.squeeze())\n",
    "union = np.logical_or(res, train_annotation.squeeze())\n",
    "sum_intersection = np.sum(intersection)\n",
    "sum_union = np.sum(union)\n",
    "\n",
    "print('%.2f%%' % ((sum_intersection/sum_union)*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
